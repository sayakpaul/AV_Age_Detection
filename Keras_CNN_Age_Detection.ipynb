{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#% pylab inline\n",
    "import os\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.misc import imread\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "root_dir = os.path.abspath('.')\n",
    "data_dir = '/media/sayak/Local Disk/AV/data'\n",
    "\n",
    "train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n",
    "test = pd.read_csv(os.path.join(data_dir, 'test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age:YOUNG\n"
     ]
    }
   ],
   "source": [
    "#%pylab inline\n",
    "from scipy.misc import imshow\n",
    "i = random.choice(train.index)\n",
    "\n",
    "img_name = train.ID[i]\n",
    "img = imread(os.path.join(data_dir, 'Train', img_name))\n",
    "\n",
    "\n",
    "imshow(img)\n",
    "print(\"Age:\" + train.Class[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.misc import imresize\n",
    "import numpy as np\n",
    "\n",
    "temp = []\n",
    "for img_name in train.ID:\n",
    "    img_path = os.path.join(data_dir, 'Train', img_name)\n",
    "    img = imread(img_path)\n",
    "    img = imresize(img, (32, 32))\n",
    "    img = img.astype('float32') # this will help us in later stage\n",
    "    temp.append(img)\n",
    "\n",
    "train_x = np.stack(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = []\n",
    "for img_name in test.ID:\n",
    "    img_path = os.path.join(data_dir, 'Test', img_name)\n",
    "    img = imread(img_path)\n",
    "    img = imresize(img, (32, 32))\n",
    "    temp.append(img.astype('float32'))\n",
    "\n",
    "test_x = np.stack(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = train_x / 255.\n",
    "test_x = test_x / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "lb = LabelEncoder()\n",
    "train_y = lb.fit_transform(train.Class)\n",
    "train_y = keras.utils.np_utils.to_categorical(train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15924 samples, validate on 3982 samples\n",
      "Epoch 1/30\n",
      "15924/15924 [==============================] - 75s - loss: 0.9646 - acc: 0.5419 - val_loss: 0.9501 - val_acc: 0.5439\n",
      "Epoch 2/30\n",
      "15924/15924 [==============================] - 71s - loss: 0.9536 - acc: 0.5425 - val_loss: 0.9426 - val_acc: 0.5439\n",
      "Epoch 3/30\n",
      "15924/15924 [==============================] - 75s - loss: 0.9386 - acc: 0.5426 - val_loss: 0.9395 - val_acc: 0.5439\n",
      "Epoch 4/30\n",
      "15924/15924 [==============================] - 74s - loss: 0.9174 - acc: 0.5446 - val_loss: 0.8964 - val_acc: 0.5525\n",
      "Epoch 5/30\n",
      "15924/15924 [==============================] - 71s - loss: 0.8946 - acc: 0.5661 - val_loss: 0.9028 - val_acc: 0.5585\n",
      "Epoch 6/30\n",
      "15924/15924 [==============================] - 69s - loss: 0.8814 - acc: 0.5801 - val_loss: 0.8679 - val_acc: 0.5816\n",
      "Epoch 7/30\n",
      "15924/15924 [==============================] - 67s - loss: 0.8686 - acc: 0.5878 - val_loss: 0.9010 - val_acc: 0.5635\n",
      "Epoch 8/30\n",
      "15924/15924 [==============================] - 69s - loss: 0.8601 - acc: 0.5977 - val_loss: 0.8564 - val_acc: 0.5944\n",
      "Epoch 9/30\n",
      "15924/15924 [==============================] - 66s - loss: 0.8488 - acc: 0.6074 - val_loss: 0.8377 - val_acc: 0.6057\n",
      "Epoch 10/30\n",
      "15924/15924 [==============================] - 66s - loss: 0.8419 - acc: 0.6144 - val_loss: 0.8490 - val_acc: 0.5846\n",
      "Epoch 11/30\n",
      "15924/15924 [==============================] - 67s - loss: 0.8296 - acc: 0.6230 - val_loss: 0.8124 - val_acc: 0.6381\n",
      "Epoch 12/30\n",
      "15924/15924 [==============================] - 65s - loss: 0.8238 - acc: 0.6257 - val_loss: 0.8033 - val_acc: 0.6467\n",
      "Epoch 13/30\n",
      "15924/15924 [==============================] - 64s - loss: 0.8152 - acc: 0.6323 - val_loss: 0.8024 - val_acc: 0.6514\n",
      "Epoch 14/30\n",
      "15924/15924 [==============================] - 66s - loss: 0.8094 - acc: 0.6375 - val_loss: 0.8060 - val_acc: 0.6406\n",
      "Epoch 15/30\n",
      "15924/15924 [==============================] - 64s - loss: 0.8105 - acc: 0.6349 - val_loss: 0.7935 - val_acc: 0.6582\n",
      "Epoch 16/30\n",
      "15924/15924 [==============================] - 69s - loss: 0.7987 - acc: 0.6466 - val_loss: 0.7847 - val_acc: 0.6625\n",
      "Epoch 17/30\n",
      "15924/15924 [==============================] - 70s - loss: 0.7999 - acc: 0.6429 - val_loss: 0.7853 - val_acc: 0.6657\n",
      "Epoch 18/30\n",
      "15924/15924 [==============================] - 71s - loss: 0.7941 - acc: 0.6475 - val_loss: 0.7851 - val_acc: 0.6532\n",
      "Epoch 19/30\n",
      "15924/15924 [==============================] - 68s - loss: 0.7965 - acc: 0.6469 - val_loss: 0.8018 - val_acc: 0.6439\n",
      "Epoch 20/30\n",
      "15924/15924 [==============================] - 73s - loss: 0.7878 - acc: 0.6510 - val_loss: 0.7799 - val_acc: 0.6590\n",
      "Epoch 21/30\n",
      "15924/15924 [==============================] - 66s - loss: 0.7884 - acc: 0.6506 - val_loss: 0.7727 - val_acc: 0.6715\n",
      "Epoch 22/30\n",
      "15924/15924 [==============================] - 71s - loss: 0.7778 - acc: 0.6557 - val_loss: 0.7751 - val_acc: 0.6673\n",
      "Epoch 23/30\n",
      "15924/15924 [==============================] - 67s - loss: 0.7823 - acc: 0.6524 - val_loss: 0.7663 - val_acc: 0.6668\n",
      "Epoch 24/30\n",
      "15924/15924 [==============================] - 65s - loss: 0.7791 - acc: 0.6574 - val_loss: 0.7723 - val_acc: 0.6637\n",
      "Epoch 25/30\n",
      "15924/15924 [==============================] - 68s - loss: 0.7751 - acc: 0.6572 - val_loss: 0.7745 - val_acc: 0.6675\n",
      "Epoch 26/30\n",
      "15924/15924 [==============================] - 73s - loss: 0.7725 - acc: 0.6577 - val_loss: 0.7630 - val_acc: 0.6695\n",
      "Epoch 27/30\n",
      "15924/15924 [==============================] - 64s - loss: 0.7714 - acc: 0.6583 - val_loss: 0.7664 - val_acc: 0.6580\n",
      "Epoch 28/30\n",
      "15924/15924 [==============================] - 62s - loss: 0.7669 - acc: 0.6634 - val_loss: 0.7580 - val_acc: 0.6755\n",
      "Epoch 29/30\n",
      "15924/15924 [==============================] - 62s - loss: 0.7665 - acc: 0.6615 - val_loss: 0.7534 - val_acc: 0.6768\n",
      "Epoch 30/30\n",
      "15924/15924 [==============================] - 64s - loss: 0.7673 - acc: 0.6590 - val_loss: 0.7567 - val_acc: 0.6755\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f86df405f28>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "\n",
    "input_num_units = (32, 32, 3)\n",
    "#hidden_num_units = 500\n",
    "#output_num_units = 3\n",
    "\n",
    "epochs = 30\n",
    "batch_size = 64\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(50, (5, 5), input_shape=(input_num_units), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(40, (5, 5), input_shape=(input_num_units), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Conv2D(30, (5, 5), input_shape=(input_num_units), activation='relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(15, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(train_x, train_y, batch_size=batch_size,epochs=epochs,verbose=1,validation_split = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6624/6636 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "pred = model.predict_classes(test_x)\n",
    "pred = lb.inverse_transform(pred)\n",
    "\n",
    "test['Class'] = pred\n",
    "test.to_csv('sub02.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
